{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_ISIC_2016.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"-dtOzHyQbFTR","colab_type":"text"},"source":["### Trains a model on the ISIC-2016 dataset"]},{"cell_type":"code","metadata":{"id":"FBbPnWmK5z5W","colab_type":"code","colab":{}},"source":["# install libs\n","!pip install image-classifiers==0.2.2\n","!pip install image-classifiers==1.0.0b1\n","!pip install imgaug\n","\n","# save files in drive\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UCMd_LsAKLxC","colab_type":"code","outputId":"d3133623-339c-4766-c751-d8ed7c3584f0","executionInfo":{"status":"ok","timestamp":1576624808585,"user_tz":300,"elapsed":2115,"user":{"displayName":"Md Hasib Zunair 1320262643","photoUrl":"","userId":"12069756592370329757"}},"colab":{"base_uri":"https://localhost:8080/","height":86}},"source":["!nvcc --version"],"execution_count":0,"outputs":[{"output_type":"stream","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2018 NVIDIA Corporation\n","Built on Sat_Aug_25_21:08:01_CDT_2018\n","Cuda compilation tools, release 10.0, V10.0.130\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PFJE3qVgJYN9","colab_type":"code","outputId":"a0cebd0f-65d5-478d-e285-93c085aa1beb","executionInfo":{"status":"ok","timestamp":1576624653863,"user_tz":300,"elapsed":525,"user":{"displayName":"Md Hasib Zunair 1320262643","photoUrl":"","userId":"12069756592370329757"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["import tensorflow as tf\n","import keras\n","\n","# Print version\n","print(\"Keras Version\", keras.__version__)\n","print(\"Tensorflow Version\", tf.__version__)\n","\n","\n","# GPU test\n","#from tensorflow.python.client import device_lib\n","#def get_available_gpus():\n","#    local_device_protos = device_lib.list_local_devices()\n","#    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n","\n","#print(get_available_gpus())\n","\n","# Get compute specs\n","#from tensorflow.python.client import device_lib\n","#device_lib.list_local_devices()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Keras Version 2.2.5\n","Tensorflow Version 1.15.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"T3jL0aXh53ml","colab_type":"code","colab":{}},"source":["# Import libs\n","import os \n","import time\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from keras import optimizers\n","import keras\n","import tensorflow as tf\n","import keras.backend as K\n","from sklearn.metrics import confusion_matrix, classification_report\n","from keras.models import load_model\n","from keras.models import Sequential\n","from keras.regularizers import l2\n","from keras.applications.vgg16 import VGG16\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, ReduceLROnPlateau\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import confusion_matrix, classification_report\n","from sklearn.metrics import roc_curve, auc, roc_auc_score\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","from keras.utils import np_utils\n","from imgaug import augmenters as iaa    \n","import itertools\n","\n","np.random.seed(42)\n","\n","# Print version\n","print(\"Keras Version\", keras.__version__)\n","print(\"Tensorflow Version\", tf.__version__)\n","\n","\n","# GPU test\n","from tensorflow.python.client import device_lib\n","def get_available_gpus():\n","    local_device_protos = device_lib.list_local_devices()\n","    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n","\n","print(get_available_gpus())\n","\n","# Get compute specs\n","from tensorflow.python.client import device_lib\n","device_lib.list_local_devices()\n","\n","\n","\n","# Helpers functions\n","\n","def create_directory(directory):\n","    '''\n","    Creates a new folder in the specified directory if the folder doesn't exist.\n","    INPUT\n","        directory: Folder to be created, called as \"folder/\".\n","    OUTPUT\n","        New folder in the current directory.\n","    '''\n","    if not os.path.exists(directory):\n","        os.makedirs(directory)\n","\n","\n","def plot_hist(img):\n","    \n","    img_flat = img.flatten()\n","    print(min(img_flat), max(img_flat))\n","    \n","    plt.hist(img_flat, bins=20, color='c')\n","    #plt.title(\"Data distribution\")\n","    plt.xlabel(\"Pixel values\")\n","    plt.grid(True)\n","    plt.ylabel(\"Frequency\")\n","    \n","    plt.show()\n","\n","\n","# Focal loss function\n","##################################################################################\n","# Paper: https://arxiv.org/abs/1708.02002\n","\n","#Focal loss down-weights the well-classified examples. This has\n","#the net effect of putting more training emphasis on that data that is hard to classify. \n","#In a practical setting where we have a data imbalance, our majority class will quickly \n","#become well-classified since we have much more data for it. Thus, in order to insure that we\n","#also achieve high accuracy on our minority class, we can use the focal loss to give those minority\n","#class examples more relative weight during training. \n","\n","from keras import backend as K\n","import tensorflow as tf\n","\n","def focal_loss(gamma=2., alpha=.25):\n","\tdef focal_loss_fixed(y_true, y_pred):\n","\t\tpt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n","\t\tpt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n","\t\treturn -K.mean(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) - K.mean((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))\n","\treturn focal_loss_fixed\n","##################################################################################\n","\n","\n","# Define paths\n","base_path = os.path.abspath(\"gdrive/My Drive/melanoma/\")\n","dataset_path = os.path.join(base_path, \"dataset\", \"isic2016numpy\")\n","model_path = os.path.join(base_path, \"models\")\n","print(os.listdir(dataset_path))\n","\n","\n","# Load data\n","x_train = np.load(\"{}/x_b2m_510.npy\".format(dataset_path)) \n","y_train = np.load(\"{}/y_b2m_510.npy\".format(dataset_path))\n","x_test = np.load(\"{}/x_test.npy\".format(dataset_path))\n","y_test = np.load(\"{}/y_test.npy\".format(dataset_path))\n","\n","\n","# Shuffle training dataset\n","flag = 1\n","if flag == 1:\n","  # Shuffle data\n","  print(\"Shuffling data\")\n","  s = np.arange(x_train.shape[0])\n","  np.random.shuffle(s)\n","  x_train = x_train[s]\n","  y_train = y_train[s]\n","else:\n","  print(\"Not shuffling...\")\n","  pass\n","\n","\n","# Flag for increasing training set\n","augment_data = False\n","augment_factor = 5 # 5x, 10x\n","\n","if augment_data is True:\n","  print(\"Increasing training set via data augmentation...\")\n","\n","  # 1\n","  seq_1 = iaa.Sequential([\n","      iaa.ContrastNormalization((0.5, 1.5)),\n","      \n","      iaa.Crop(percent=(0, 0.2)), # random crops\n","      # Small gaussian blur with random sigma between 0 and 0.5.\n","      # But we only blur about 50% of all images.\n","      iaa.Sometimes(0.5,\n","          iaa.GaussianBlur(sigma=(0, 0.5))\n","      ),\n","      iaa.Sometimes(0.7, \n","          iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5)\n","      ),\n","      # Make some images brighter and some darker.\n","      # In 20% of all cases, we sample the multiplier once per channel,\n","      # which can end up changing the color of the images.\n","      #iaa.Multiply((0.8, 1.2), per_channel=0.2),\n","      \n","      iaa.Affine(\n","          rotate=(-25, 25),\n","      ),\n","      iaa.Affine(\n","          translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n","      ),\n","      iaa.Affine(\n","          shear=(-25, 25)\n","      ),\n","      \n","      iaa.Sometimes(0.8, \n","          iaa.CoarseDropout(0.03, size_percent=0.1)\n","      ),\n","      iaa.Sequential([\n","          iaa.ChangeColorspace(from_colorspace=\"RGB\", to_colorspace=\"HSV\"),\n","          iaa.WithChannels(0, iaa.Add((50, 100))),\n","          iaa.ChangeColorspace(from_colorspace=\"HSV\", to_colorspace=\"RGB\")\n","      ]),\n","      \n","  ], random_order=True) # apply augmenters in random order\n","\n","\n","\n","  # 2\n","  seq_2 = iaa.Sequential([\n","      iaa.ContrastNormalization((0.5, 1.5)),\n","      iaa.Sometimes(0.5,\n","          iaa.GaussianBlur(sigma=(0, 0.5))\n","      ),\n","      iaa.Sometimes(0.7, \n","          iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255), per_channel=0.5)\n","      ),\n","      iaa.Affine(\n","          rotate=(-25, 25),\n","      ),\n","      iaa.Affine(\n","          translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n","      ),\n","      iaa.Affine(\n","          shear=(-25, 25)\n","      ),\n","  ], random_order=True) # apply augmenters in random order\n","\n","\n","\n","  def augment_data_minimal( x_values, y_values ):\n","      counter = 0\n","      RESIZE_DIM = 256\n","      X_values_augmented = []\n","      Y_values_augmented = []\n","      for x in x_values:\n","          for p in range(augment_factor):\n","              \n","              # seq 1\n","              Y_values_augmented.append( y_values[counter] )\n","              images_aug = seq_1.augment_images(x.reshape(1,RESIZE_DIM,RESIZE_DIM,3))   \n","              X_values_augmented.append( images_aug.reshape(RESIZE_DIM,RESIZE_DIM,3))\n","\n","              # seq 2\n","              #Y_values_augmented.append( y_values[counter] )\n","              #images_aug = seq_2.augment_images(x.reshape(1,RESIZE_DIM,RESIZE_DIM,3))   \n","              #X_values_augmented.append( images_aug.reshape(RESIZE_DIM,RESIZE_DIM,3))\n","\n","          counter = counter + 1\n","      \n","      # Quick math!\n","      # prev number of images = n\n","      # augmented number of images = n * 5 ( 2 seq 2 times)\n","      \n","      X_values_augmented = np.asarray( X_values_augmented )\n","      Y_values_augmented = np.asarray( Y_values_augmented )\n","      return (X_values_augmented, Y_values_augmented)\n","\n","  (x_aug, y_aug) = augment_data_minimal( x_train, y_train)\n","  print(\"Augmented sample size: \", x_aug.shape, y_aug.shape)\n","\n","  x_train = np.concatenate( (x_train, x_aug), axis = 0)\n","  y_train = np.concatenate( (y_train, y_aug), axis = 0)\n","\n","else:\n","  print(\"Not increasing dataset via augmentation..\")\n","  pass\n","\n","\n","# Show shape\n","print(\"Dataset sample size :\", x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n","\n","\n","# Sanity check on training data\n","#img = x_train[0]\n","#plot_hist(img)\n","\n","#plt.imshow(x_train[0])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mkxe1Mp26ZQi","colab_type":"code","colab":{}},"source":["# Import libs\n","import keras\n","from classification_models.keras import Classifiers\n","\n","# Define architecture\n","arch, preprocess_input = Classifiers.get('vgg16') \n","\n","\n","# Preprocess the dataset\n","\n","# 1. Use model preprocessing\n","#x_train = preprocess_input(x_train)\n","#x_test = preprocess_input(x_test)\n","\n","\n","# 2. Use standard preprocessing\n","prepro = False # False when using synthetic data\n","\n","if prepro == True:\n","  print(\"Preprocessing training data\")\n","  x_train = x_train.astype('float32')\n","  x_train /= 255\n","else:\n","  print(\"Not preprocessing training data, already preprocessed in MeGAN generator.\")\n","  pass\n","\n","# Standardize test set\n","x_test = x_test.astype('float32')\n","x_test /= 255\n","\n","print(x_train.shape, x_test.shape)\n","\n","# Sanity check on preprocessed data\n","#img = x_test[0]\n","#plot_hist(img)\n","#plt.imshow(x_test[0])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"teeONwaw6ZYa","colab_type":"code","colab":{}},"source":["# Experiment name\n","EXP_NAME = \"b2m_510_2nd\"\n","\n","# Create folder for the experiment\n","create_directory(\"{}/{}\".format(base_path, EXP_NAME))\n","output_path = os.path.join(base_path, EXP_NAME)\n","\n","\n","# Callbacks\n","weights_path = \"{}/{}.h5\".format(output_path, EXP_NAME)\n","checkpointer = ModelCheckpoint(filepath=weights_path, verbose=1, monitor='val_loss', save_best_only=True)\n","reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, min_lr=1e-8, mode='auto') # new_lr = lr * factor\n","early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, verbose=1, patience=8, mode='auto', restore_best_weights=True)\n","csv_logger = CSVLogger('{}/{}_training.csv'.format(output_path, EXP_NAME))\n","\n","\n","# Define class weights for imbalacned data\n","from sklearn.utils import class_weight\n","class_weights = class_weight.compute_class_weight('balanced', np.unique(np.argmax(y_train, axis=1)), np.argmax(y_train, axis=1))\n","print(class_weights)\n","\n","\n","def my_awesome_model():\n","  \n","  '''Awesomest model'''\n","\n","  # Get backbone network\n","  base_model = arch(input_shape=(256,256,3), weights='imagenet', include_top=False)\n","  \n","  # Add GAP layer\n","  x = keras.layers.GlobalAveragePooling2D()(base_model.output)\n","  # Add FC layer\n","  output = keras.layers.Dense(2, activation='softmax', trainable=True)(x) \n","\n","  # Freeze layers\n","  #for layer in base_model.layers[:]:\n","    #layer.trainable=False\n","  \n","  # Build model\n","  model = keras.models.Model(inputs=[base_model.input], outputs=[output])\n","\n","  # Optimizers\n","  adadelta = optimizers.Adadelta(lr=0.001) \n","  \n","  # Compile\n","  model.compile(optimizer=adadelta, loss= [focal_loss(alpha=.25, gamma=2)], metrics=['accuracy']) \n","  \n","  # Output model configuration\n","  model.summary()\n","\n","  return model\n","\n","\n","model = None\n","model = my_awesome_model()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"F43HGExG6ZbU","colab_type":"code","colab":{}},"source":["# Train the awesome model\n","\n","# Configuration\n","batch_size = 16\n","epochs = 300 \n","\n","# Flag for on-the-fly data augmentation\n","data_augmentation = False\n","\n","# Calculate the starting time    \n","start_time = time.time()\n","\n","\n","def train_model(epochs):\n","  if not data_augmentation:\n","      print('Not using data augmentation.')\n","      model.fit(x_train, y_train,\n","                batch_size=batch_size,\n","                epochs=epochs,\n","                validation_data=(x_test, y_test),\n","                class_weight = class_weights,\n","                callbacks=[csv_logger, early_stopping, reduce_lr, checkpointer], # early_stopping, checkpointer, reduce_lr\n","                shuffle=False)\n","  else:\n","      print('Using real-time data augmentation.')\n","      # This will do preprocessing and realtime data augmentation:\n","      datagen = ImageDataGenerator(\n","          featurewise_center=False,  # set input mean to 0 over the dataset\n","          samplewise_center=False,  # set each sample mean to 0\n","          featurewise_std_normalization=False,  # divide inputs by std of the dataset\n","          samplewise_std_normalization=False,  # divide each input by its std\n","          zca_whitening=False,  # apply ZCA whitening\n","          zca_epsilon=1e-06,  # epsilon for ZCA whitening\n","          rotation_range=180,  # randomly rotate images in the range (degrees, 0 to 180)\n","          width_shift_range=0.25, # randomly shift images horizontally (fraction of total width)\n","          height_shift_range=0.25, # randomly shift images vertically (fraction of total height)\n","          shear_range=0.2,  # set range for random shear\n","          zoom_range=0.2,  # set range for random zoom\n","          channel_shift_range=0.,  # set range for random channel shifts\n","          fill_mode='nearest', # set mode for filling points outside the input boundaries\n","          cval=0.,  # value used for fill_mode = \"constant\"\n","          horizontal_flip=True,  # randomly flip images\n","          vertical_flip=True,  # randomly flip images\n","          rescale=None, # set rescaling factor (applied before any other transformation)\n","          preprocessing_function=None, # set function that will be applied on each input\n","          data_format=None, # image data format, either \"channels_first\" or \"channels_last\"\n","          # fraction of images reserved for validation (strictly between 0 and 1)\n","          validation_split=0.0)\n","\n","      # Compute quantities required for feature-wise normalization\n","      # (std, mean, and principal components if ZCA whitening is applied).\n","      datagen.fit(x_train)\n","\n","      # Fit the model on the batches generated by datagen.flow().\n","      model.fit_generator(datagen.flow(x_train, y_train,\n","                                      batch_size=batch_size),epochs=epochs,\n","                          validation_data=(x_test, y_test),\n","                          #class_weight = class_weights,\n","                          callbacks=[csv_logger])\n","    \n","\n","\n","# Warm up training: train the newly added blocks\n","#train_model(epochs=10)\n","#print(\"Releasing all layers...\")\n","# release all layers for training, set all layers trainable and recompile\n","#set_trainable(model)\n","#print(model.summary())\n","\n","# run training\n","train_model(epochs=epochs)\n","\n","\n","end_time = time.time()\n","print(\"--- Time taken to train : %s hours ---\" % ((end_time - start_time)//3600))\n","\n","# Save model\n","# If checkpointer is used, dont use this\n","model.save(weights_path)\n","\n","\n","# Plot and save accuravy loss graphs together\n","def plot_loss_accu_all(history):\n","    \n","    loss = history.history['loss']\n","    val_loss = history.history['val_loss']\n","    acc = history.history['acc']\n","    val_acc = history.history['val_acc']\n","    epochs = range(len(loss))\n","    \n","    plt.plot(epochs, acc, 'r')\n","    plt.plot(epochs, val_acc, 'b')\n","    plt.plot(epochs, loss, 'g')\n","    plt.plot(epochs, val_loss, 'y')\n","    plt.title('Accuracy/Loss')\n","    \n","    #plt.ylabel('Rate')\n","    #plt.xlabel('Epoch')\n","    \n","    plt.legend(['trainacc', 'valacc', 'trainloss', 'valloss'], loc='lower right', fontsize=10)\n","    plt.grid(True)\n","    plt.savefig('{}/{}_acc_loss_graph.jpg'.format(output_path, EXP_NAME), dpi=100)\n","    plt.show()\n","\n","# Plot and save accuravy loss graphs individually\n","def plot_loss_accu(history):\n","    loss = history.history['loss']\n","    val_loss = history.history['val_loss']\n","    epochs = range(len(loss))\n","    plt.plot(epochs, loss, 'g')\n","    plt.plot(epochs, val_loss, 'y')\n","    #plt.title('Training and validation loss')\n","    plt.ylabel('Loss %')\n","    plt.xlabel('Epoch')\n","    plt.legend(['train', 'val'], loc='upper right')\n","    plt.grid(True)\n","    #plt.savefig('{}/{}_loss.jpg'.format(output_path, EXP_NAME), dpi=100)\n","    plt.savefig('{}/{}_loss.pdf'.format(output_path, EXP_NAME), dpi=300)\n","    plt.show()\n","    \n","    loss = history.history['acc']\n","    val_loss = history.history['val_acc']\n","    epochs = range(len(loss))\n","    plt.plot(epochs, loss, 'r')\n","    plt.plot(epochs, val_loss, 'b')\n","    #plt.title('Training and validation accuracy')\n","    plt.ylabel('Accuracy %')\n","    plt.xlabel('Epoch')\n","    plt.legend(['train', 'val'], loc='lower right')\n","    plt.grid(True)\n","    #plt.savefig('{}/{}_acc.jpg'.format(output_path, EXP_NAME), dpi=100)\n","    plt.savefig('{}/{}_acc.pdf'.format(output_path, EXP_NAME), dpi=300)\n","    plt.show()\n","\n","plot_loss_accu(model.history)\n","print(\"Done training and logging!\")\n","\n","######################\n","# Define report \n","#report = {}\n","\n","# save metric report\n","#print(report)\n","\n","#with open(\"{}/{}_report.json\".format(output_path, EXP_NAME), 'w') as f:\n","    #for k,v in report.items():\n","        #f.write(str(k))\n","        #f.write(\"--->\")\n","        #f.write(str(v))\n","        \n","        # new line\n","        #f.write(\"\\n\")\n","\n","#f.close()\n","######################"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"csbkPKondraG","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}