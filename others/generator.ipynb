{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create minority sample using translation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import scipy\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import keras\n",
    "import pandas as pd\n",
    "from keras.datasets import mnist\n",
    "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Concatenate\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "sys.path.append(ROOT_DIR)  \n",
    "import helpers\n",
    "\n",
    "# Training file directory\n",
    "DATASET = os.path.join(ROOT_DIR, 'dataset')\n",
    "\n",
    "PATH = \"{}/{}\".format(DATASET, \"isic2016numpy\")\n",
    "# load data\n",
    "x_train = np.load(\"{}/x_train.npy\".format(PATH))\n",
    "y_train = np.load(\"{}/y_train.npy\".format(PATH))\n",
    "x_train.shape, y_train.shape\n",
    "\n",
    "MODEL_PATH = os.path.join(ROOT_DIR, \"models\")\n",
    "print(ROOT_DIR)\n",
    "print(os.listdir(MODEL_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b2m_510 done\n",
    "#b2m_597 done\n",
    "#b2m_784 done\n",
    "\n",
    "model_name = 'generator_isic2016_b2m_100.h5'\n",
    "model = load_model(os.path.join(MODEL_PATH, model_name), custom_objects={'InstanceNormalization':InstanceNormalization})\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, img):\n",
    "    \n",
    "    if img.shape[0] != 256:\n",
    "        print(\"Resizing image..\")\n",
    "        img = cv2.resize(img, (256, 256))\n",
    "    \n",
    "    # Normalize image as the trained distribution\n",
    "    \n",
    "    img = img/127.5 - 1.\n",
    "    \n",
    "    # Normalize imgae [0, 1]\n",
    "    #img = img.astype('float32')\n",
    "    #img /= 255.\n",
    "    \n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = model.predict(img)\n",
    "    img = np.squeeze(img, axis=0)\n",
    "    \n",
    "    \n",
    "    # Rescale to [0,1]\n",
    "    #img = 0.5 * img + 0.5\n",
    "    img = (img - np.min(img))/np.ptp(img)\n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "def oversample(x, y, model):\n",
    "    '''\n",
    "    Some cool stuff\n",
    "    INPUT\n",
    "        x: \n",
    "        y:\n",
    "        model:\n",
    "        \n",
    "    OUTPUT\n",
    "        New folder in the current directory.\n",
    "    '''\n",
    "    \n",
    "    print(\"Before oversampling :\", x.shape, y.shape)\n",
    "    \n",
    "    \n",
    "    # majority class\n",
    "    majority_samples = []\n",
    "    for img, label in zip(x, y):\n",
    "        if label[1] == 0:\n",
    "            majority_samples.append(img)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    # numpy array of majority classes\n",
    "    majority_samples = np.array(majority_samples)\n",
    "    \n",
    "    # minority generated samples\n",
    "    synthetic_samples = []\n",
    "    \n",
    "    # iterate over majority samples and generate minority class\n",
    "    for img in tqdm(majority_samples):\n",
    "        \n",
    "        # translate to malignant\n",
    "        pred = predict(model, img)\n",
    "        synthetic_samples.append(pred)\n",
    "    \n",
    "    # make labels for generated minority classes\n",
    "    y_syn = np.array([1 for _ in range(len(synthetic_samples))])\n",
    "    y_syn = np_utils.to_categorical(y_syn, 2)\n",
    "    \n",
    "    # Scale training set to [0, 1]\n",
    "    x = x.astype('float32')\n",
    "    x /= 255\n",
    "    \n",
    "    # merge and shuffle training and generated samples\n",
    "    x_balanced = np.concatenate( (x, synthetic_samples), axis = 0)\n",
    "    y_balanced = np.concatenate( (y, y_syn), axis = 0)\n",
    "    x_balanced, y_balanced = helpers.shuffle_dataset(x_balanced, y_balanced)\n",
    "    \n",
    "    assert len(majority_samples) == len(synthetic_samples), \"This should be same! If not, check model code\"\n",
    "    assert len(x_balanced) == len(synthetic_samples) + len(x_train), \"Check oversampler code\"\n",
    "    print(\"After oversampling: \", x_balanced.shape, y_balanced.shape)\n",
    "    \n",
    "    return majority_samples, synthetic_samples, x_balanced, y_balanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw, gen, x_new, y_new = oversample(x_train, y_train, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divide the synthetic malignant from raw dataset for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = np.array(gen)\n",
    "print(gen.shape)\n",
    "\n",
    "# make new label for plotting\n",
    "gen_label = np.array([2 for _ in range(len(gen))])\n",
    "gen_label = np_utils.to_categorical(gen_label, 3)\n",
    "print(gen_label.shape)\n",
    "\n",
    "# change original label to 3 onehot encoded vector\n",
    "y_3 = np.array([np.argmax(x) for x in y_train])\n",
    "print(y_3.shape)\n",
    "y_3 = np_utils.to_categorical(y_3, 3)\n",
    "print(y_3.shape)\n",
    "\n",
    "\n",
    "# Scale training set to [0, 1] as synthetic data is in that range\n",
    "x_train = x_train.astype('float32')\n",
    "x_train /= 255\n",
    "    \n",
    "# merge and shuffle training and generated samples\n",
    "x_balanced = np.concatenate( (x_train, gen), axis = 0)\n",
    "y_balanced = np.concatenate( (y_3, gen_label), axis = 0)\n",
    "#x3, y3 = helpers.shuffle_dataset(x_balanced, y_balanced)\n",
    "x3, y3 = x_balanced, y_balanced\n",
    "print(x3.shape, y3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend.clear_session()\n",
    "model = None\n",
    "model_name = \"MelaNet.h5\"\n",
    "model = load_model(os.path.join(MODEL_PATH, model_name), custom_objects={'InstanceNormalization':InstanceNormalization}, compile=False)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(x3[0].flatten()), max(x3[0].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "layer_name = 'global_average_pooling2d_1'\n",
    "intermediate_layer_model = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer(layer_name).output)\n",
    "\n",
    "intermediate_output = intermediate_layer_model.predict(x3, verbose=1)\n",
    "intermediate_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_output.shape, y3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "resized_images = []\n",
    "for i in range(len(x3)):\n",
    "    img = cv2.resize(x3[i], (20,20), interpolation = cv2.INTER_AREA)\n",
    "    resized_images.append(img) \n",
    "    \n",
    "resized_images = np.array(resized_images)\n",
    "resized_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn, sklearn.manifold\n",
    "\n",
    "X_embedded = sklearn.manifold.TSNE(n_components=2, random_state=42).fit_transform(intermediate_output)\n",
    "X_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, 16))\n",
    "for item in range(X_embedded.shape[0]):\n",
    "    ax.scatter(X_embedded[item,0], X_embedded[item,1])\n",
    "    #plt.annotate(str(item),(X_embedded[item,0], X_embedded[item,1]))\n",
    "    ab = AnnotationBbox(OffsetImage(resized_images[item], cmap=\"Greys_r\"),  #resized_images[item][0]\n",
    "                        (X_embedded[item,0], X_embedded[item,1]), frameon=False)\n",
    "    ax.add_artist(ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(0, figsize=(7, 7), dpi=100)\n",
    "plt.scatter(X_embedded[:,0], X_embedded[:,1])\n",
    "x = np.linspace(-70,70,2)\n",
    "y = 0*x+40\n",
    "plt.plot(x, y, '-r', label='y=2x+1');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot raw data UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import time\n",
    "from sklearn.datasets import fetch_openml\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "sns.set(context=\"paper\", style=\"white\")\n",
    "\n",
    "raw_train = intermediate_output #x3\n",
    "raw_annot = y3\n",
    "\n",
    "\n",
    "print(raw_train.shape)\n",
    "raw_t_s = np.array([img.flatten() for img in raw_train])\n",
    "print(raw_t_s.shape)\n",
    "print(raw_annot.shape)\n",
    "raw_annot_flat = np.argmax(raw_annot, axis=1)\n",
    "print(raw_annot_flat.shape)\n",
    "\n",
    "raw_annot_flat_3 = raw_annot_flat\n",
    "print(np.unique(raw_annot_flat_3))\n",
    "print(raw_t_s.shape, raw_annot_flat_3.shape)\n",
    "\n",
    "\n",
    "data = raw_t_s\n",
    "\n",
    "reducer = umap.UMAP(n_neighbors=15, random_state=42)\n",
    "embedding = reducer.fit_transform(data)\n",
    "\n",
    "colour_map = raw_annot_flat_3\n",
    "\n",
    "tsneFigure = plt.figure(figsize=(12, 10))\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "for colour in range(2): # 1 - benign only, 2- malig benign, 3 - malig benign synth malig\n",
    "    indices = np.where(colour_map==colour)\n",
    "    indices = indices[0]\n",
    "    \n",
    "    if colour == 0:\n",
    "        l = \"Benign\"\n",
    "    if colour == 1:\n",
    "        l = \"Malignant\"\n",
    "    if colour == 2:\n",
    "        l = \"Generated Malignant\"\n",
    "\n",
    "    plt.setp(ax, xticks=[], yticks=[])\n",
    "    plt.scatter(embedding[:, 0][indices],\n",
    "                embedding[:, 1][indices],\n",
    "                label=None, cmap=\"Spectral\", s=50)\n",
    "    \n",
    "\n",
    "#plt.legend(loc='lower left', prop={'size': 20})\n",
    "plt.axis('off')\n",
    "#plt.savefig(\"raw_UMAP.pdf\", bbox_inches = 'tight', pad_inches = 0, dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import time\n",
    "from sklearn.datasets import fetch_openml\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "sns.set(context=\"paper\", style=\"white\")\n",
    "\n",
    "raw_train = intermediate_output #x3\n",
    "raw_annot = y3\n",
    "\n",
    "\n",
    "print(raw_train.shape)\n",
    "raw_t_s = np.array([img.flatten() for img in raw_train])\n",
    "print(raw_t_s.shape)\n",
    "print(raw_annot.shape)\n",
    "raw_annot_flat = np.argmax(raw_annot, axis=1)\n",
    "print(raw_annot_flat.shape)\n",
    "\n",
    "raw_annot_flat_3 = raw_annot_flat\n",
    "print(np.unique(raw_annot_flat_3))\n",
    "print(raw_t_s.shape, raw_annot_flat_3.shape)\n",
    "\n",
    "\n",
    "data = raw_t_s\n",
    "\n",
    "reducer = umap.UMAP(n_neighbors=15, random_state=42)\n",
    "embedding = reducer.fit_transform(data)\n",
    "\n",
    "colour_map = raw_annot_flat_3\n",
    "\n",
    "tsneFigure = plt.figure(figsize=(12, 10))\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "for colour in range(3): # 1 - benign only, 2- malig benign, 3 - malig benign synth malig\n",
    "    indices = np.where(colour_map==colour)\n",
    "    indices = indices[0]\n",
    "    \n",
    "    if colour == 0:\n",
    "        l = \"Benign\"\n",
    "    if colour == 1:\n",
    "        l = \"Malignant\"\n",
    "    if colour == 2:\n",
    "        l = \"Generated Malignant\"\n",
    "\n",
    "    plt.setp(ax, xticks=[], yticks=[])\n",
    "    plt.scatter(embedding[:, 0][indices],\n",
    "                embedding[:, 1][indices],\n",
    "                label=None, cmap=\"Spectral\", s=50)\n",
    "    \n",
    "\n",
    "#plt.legend(loc='lower left', prop={'size': 20})\n",
    "plt.axis('off')\n",
    "#plt.savefig(\"gan_UMAP.pdf\", bbox_inches = 'tight', pad_inches = 0, dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualized and save the oversampled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inital dataset + generated samples\n",
    "x_new.shape, y_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max(np.array(gen).flatten()), min(np.array(gen).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max(x_new.flatten()), min(x_new.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import rand\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "index = np.random.choice(np.array(gen).shape[0], 30, replace=False)\n",
    "raw = np.array(raw)\n",
    "x = raw[index]\n",
    "\n",
    "a, b = 5, 6\n",
    "x = np.reshape(x, (a, b, 256, 256, 3))\n",
    "\n",
    "\n",
    "test_data = x\n",
    "r, c = test_data.shape[0], test_data.shape[1]\n",
    "cmaps = [['viridis', 'binary'], ['plasma', 'coolwarm'], ['Greens', 'copper']]\n",
    "\n",
    "heights = [a[0].shape[0] for a in test_data]\n",
    "widths = [a.shape[1] for a in test_data[0]]\n",
    "\n",
    "fig_width = 15.  # inches\n",
    "fig_height = fig_width * sum(heights) / sum(widths)\n",
    "\n",
    "f, axarr = plt.subplots(r,c, figsize=(fig_width, fig_height),\n",
    "        gridspec_kw={'height_ratios':heights})\n",
    "\n",
    "for i in range(r):\n",
    "    for j in range(c):\n",
    "        axarr[i, j].imshow(test_data[i][j])\n",
    "        axarr[i, j].axis('off')\n",
    "        \n",
    "plt.subplots_adjust(wspace=0, hspace=0, left=0, right=1, bottom=0, top=1)\n",
    "plt.savefig('{}/{}.png'.format(\"{}/outputs/\".format(ROOT_DIR), \"beforegan\"), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthesize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import rand\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gen = np.array(gen)\n",
    "x = gen[index]\n",
    "\n",
    "a, b = 5, 6\n",
    "x = np.reshape(x, (a, b, 256, 256, 3))\n",
    "\n",
    "\n",
    "test_data = x\n",
    "r, c = test_data.shape[0], test_data.shape[1]\n",
    "cmaps = [['viridis', 'binary'], ['plasma', 'coolwarm'], ['Greens', 'copper']]\n",
    "\n",
    "heights = [a[0].shape[0] for a in test_data]\n",
    "widths = [a.shape[1] for a in test_data[0]]\n",
    "\n",
    "fig_width = 15.  # inches\n",
    "fig_height = fig_width * sum(heights) / sum(widths)\n",
    "\n",
    "f, axarr = plt.subplots(r,c, figsize=(fig_width, fig_height),\n",
    "        gridspec_kw={'height_ratios':heights})\n",
    "\n",
    "for i in range(r):\n",
    "    for j in range(c):\n",
    "        axarr[i, j].imshow(test_data[i][j])\n",
    "        axarr[i, j].axis('off')\n",
    "        \n",
    "plt.subplots_adjust(wspace=0, hspace=0, left=0, right=1, bottom=0, top=1)\n",
    "plt.savefig('{}/{}.png'.format(\"{}/outputs/\".format(ROOT_DIR), \"aftergan\"), dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helpers.show_images(raw[-20:], cols = 3, titles = None, save_fig = \"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helpers.show_images(gen[-20:], cols = 3, titles = None, save_fig = \"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([np.argmax(y) for y in y_new])\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(a == 0), np.count_nonzero(a == 1)\n",
    "#np.count_nonzero(a == 0), np.count_nonzero(a == 1), np.count_nonzero(a == 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new.shape, y_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory\n",
    "helpers.create_directory(\"{}/dataset/isic2016gan/\".format(ROOT_DIR))\n",
    "\n",
    "\n",
    "# Save\n",
    "np.save(\"{}/dataset/isic2016gan/{}{}.npy\".format(ROOT_DIR, \"x_\", model_name[:-3]), x_new)\n",
    "np.save(\"{}/dataset/isic2016gan/{}{}.npy\".format(ROOT_DIR, \"y_\", model_name[:-3]), y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
